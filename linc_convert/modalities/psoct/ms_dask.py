"""
Matlab to OME-Zarr.

Converts Matlab files generated by the MGH in-house OCT pipeline
into a OME-ZARR pyramid.

WARNING: THIS IS ONLY FOR TESTING IO. NEVER USE FOR PRODUCTION
"""

import json
import os
from functools import wraps
from itertools import product
from typing import Callable, Mapping, Optional
from warnings import warn
import logging

import cyclopts
import dask.array
import h5py
import numpy as np
from dask import delayed
from scipy.io import loadmat

from linc_convert import utils
from linc_convert.modalities.psoct._utils import make_json
from linc_convert.modalities.psoct.cli import psoct
from linc_convert.utils.math import ceildiv
from linc_convert.utils.orientation import center_affine, orientation_to_affine
from linc_convert.utils.unit import to_nifti_unit, to_ome_unit
from linc_convert.utils.zarr import open_zarr_group, create_array, generate_pyramid
from niizarr import default_nifti_header, write_nifti_header, write_ome_metadata
import dask.array as da

from linc_convert.utils.zarr.zarr_config import ZarrConfig

logger = logging.getLogger(__name__)
ms = cyclopts.App(name="ms", help_format="markdown")
psoct.command(ms)


def _automap(func: Callable) -> Callable:
    """Automatically maps the array in the mat file."""

    @wraps(func)
    def wrapper(inp: list[str], **kwargs: dict) -> callable:
        dat = _mapmat(inp, kwargs.get("key", None))
        return func(dat, **kwargs)
    return wrapper


class _ArrayWrapper:
    def _get_key(self, f: Mapping) -> str:
        key = self.key
        if key is None:
            if not len(f.keys()):
                raise Exception(f"{self.file} is empty")
            # Select the first non-hidden key
            for key in f.keys():
                if key[0] != "_":
                    break
            if len(f.keys()) > 1:
                warn(
                    f"More than one key in .mat file {self.file}, "
                    f'arbitrarily loading "{key}"'
                )

        if key not in f.keys():
            raise Exception(f"Key {key} not found in file {self.file}")
        return key


class _H5ArrayWrapper(_ArrayWrapper):
    def __init__(self, file: h5py.File, key: Optional[str]) -> None:
        self.file = file
        self.key = key
        self.array = file.get(self._get_key(self.file))

    def __del__(self) -> None:
        if hasattr(self.file, "close"):
            self.file.close()

    def load(self) -> np.ndarray:
        self.array = self.array[...]
        if hasattr(self.file, "close"):
            self.file.close()
        self.file = None
        return self.array

    @property
    def shape(self) -> list[int]:
        return self.array.shape

    @property
    def dtype(self) -> np.dtype:
        return self.array.dtype

    def __len__(self) -> int:
        return len(self.array)

    def __getitem__(self, index: object) -> np.ndarray:
        return self.array[index]


class _MatArrayWrapper(_ArrayWrapper):
    def __init__(self, file: str, key: Optional[str]) -> None:
        self.file = file
        self.key = key
        self.array = None

    def __del__(self) -> None:
        if hasattr(self.file, "close"):
            self.file.close()

    def load(self) -> np.ndarray:
        if self.array is not None:
            return self.array

        data = loadmat(self.file)
        self.array = data.get(self._get_key(data))
        self.file = None
        return self.array

    @property
    def shape(self) -> list[int]:
        if self.array is None:
            self.load()
        return self.array.shape

    @property
    def dtype(self) -> np.dtype:
        if self.array is None:
            self.load()
        return self.array.dtype

    def __len__(self) -> int:
        if self.array is None:
            self.load()
        return len(self.array)

    def __getitem__(self, index: object) -> np.ndarray:
        if self.array is None:
            self.load()
        return self.array[index]


def _mapmat(fnames: list[str], key: Optional[str] = None) -> list[_ArrayWrapper]:
    """Load or memory-map an array stored in a .mat file."""
    def make_wrapper(fname: str) -> _ArrayWrapper:
        try:
            # "New" .mat file
            f = h5py.File(fname, "r")
            return _H5ArrayWrapper(f, key)
        except Exception:
            # "Old" .mat file
            return _MatArrayWrapper(fname, key)

    return [make_wrapper(fname) for fname in fnames]

@ms.default
@_automap
def convert(
    inp: list[str],
    *,
    zarr_config: ZarrConfig = None,
    key: Optional[str] = None,
    meta: str = None,
    orientation: str = "RAS",
    center: bool = True,
    dtype: Optional[str] = None,
    **kwargs
) -> None:
    """
    Matlab to OME-Zarr.

    Convert OCT volumes in raw matlab files into a pyramidal
    OME-ZARR (or NIfTI-Zarr) hierarchy.

    This command assumes that each slice in a volume is stored in a
    different mat file. All slices must have the same shape and will be
    concatenated into a 3D Zarr.

    Parameters
    ----------
    inp : list of str
        Paths to the input mat files.
    key : Optional[str]
        Key of the array to be extracted; defaults to the first key found.
    meta : str
        Path to the metadata file.
    orientation : str
        Orientation of the volume.
    center : bool
        Set RAS[0, 0, 0] at FOV center.
    dtype : Optional[str]
        Data type to write into.
    """
    zarr_config = utils.zarr.zarr_config.update(zarr_config, **kwargs)
    zarr_config.set_default_name(os.path.splitext(inp[0].file)[0])

    # Process metadata if provided
    if meta:
        logger.info("Writing JSON metadata")
        with open(meta, "r") as f:
            meta_txt = f.read()
            meta_json = make_json(meta_txt)
        path_json = ".".join(zarr_config.out.split(".")[:-2]) + ".json"
        with open(path_json, "w") as f:
            json.dump(meta_json, f, indent=4)
        vx = meta_json["PixelSize"]
        unit = meta_json["PixelSizeUnits"]
    else:
        vx = [1, 1, 1]
        unit = "um"

    # Prepare Zarr group
    omz = open_zarr_group(zarr_config)

    # if not hasattr(inp[0], "dtype"):
    #     raise Exception("Input is not an array. This is likely unexpected")
    if len(inp[0].shape) < 2:
        raise ValueError(f"Input array is not 2D: {inp[0].shape}")

    dtype = dtype or np.dtype(inp[0].dtype).str
    nslices = len(inp)
    data = [delayed(inp[i].load)() for i in range(nslices)]
    slices = [da.from_delayed(i, shape=inp[0].shape, dtype=dtype) for i in data]
    full_volume = da.concatenate(slices, axis=2)
    volume_shape = full_volume.shape

    dataset = create_array(omz, "0", shape=full_volume.shape, zarr_config=zarr_config,
                           dtype=np.dtype(dtype))
    if dataset.shards is None:
        full_volume.to_zarr(dataset)
    else:
        full_volume = full_volume.rechunk(dataset.shards)
        def save(chunk,block_info=None):
            slicer = tuple(slice(*al) for al in block_info[0]['array-location'])
            dataset[slicer] = chunk
            return np.zeros_like(chunk)
        full_volume.map_blocks(save,dtype=np.uint8).compute()


    generate_pyramid(omz, mode="mean", no_pyramid_axis=zarr_config.no_pyramid_axis)
    logger.info("Write OME-Zarr multiscale metadata")
    write_ome_metadata(omz, axes=["z", "y", "x"], space_unit=to_ome_unit(unit))

    if not zarr_config.nii:
        logger.info("Conversion complete.")
        return

    # Write NIfTI-Zarr header
    arr = omz["0"]
    header, _ = default_nifti_header(arr, omz.attrs.get("ome", omz.attrs).get("multiscales"))
    reversed_shape = list(reversed(arr.shape))
    affine = orientation_to_affine(orientation, *vx[::-1])
    if center:
        affine = center_affine(affine, reversed_shape[:3])
    header.set_data_shape(reversed_shape)
    header.set_data_dtype(arr.dtype)
    header.set_qform(affine)
    header.set_sform(affine)
    header.set_xyzt_units(to_nifti_unit(unit))

    write_nifti_header(omz, header)

