# stdlib
import ast
import os
import re
import warnings
from collections import namedtuple, defaultdict
from glob import glob

# externals
import cyclopts
import nibabel as nib
import numpy as np
import zarr
from niizarr import default_nifti_header, write_nifti_header
from niizarr._nii2zarr import write_ome_metadata

# internals
from linc_convert import utils
from linc_convert.modalities.lsm.cli import lsm
from linc_convert.utils.orientation import center_affine, orientation_to_affine
from linc_convert.utils.spool import SpoolSetInterpreter
from linc_convert.utils.zarr.compressor import make_compressor
from linc_convert.utils.zarr.generate_pyramid import generate_pyramid
from linc_convert.utils.zarr.zarr_config import ZarrConfig

spool = cyclopts.App(name="spool", help_format="markdown")
lsm.command(spool)

"""
Convert a collection of tiff files generated by the LSM pipeline into a Zarr.

Example input files can be found at
https://lincbrain.org/dandiset/000010/draft/files?location=sourcedata%252Fderivatives
"""


@spool.default
def convert(
        inp: str,
        *,
        out: str,
        zarr_config: ZarrConfig = None,
        overlap: int = 30,
        max_load: int = 512,
        orientation: str = "coronal",
        center: bool = True,
        voxel_size: list[float] = (1, 1, 1),
        **kwargs
) -> None:
    """
    Convert a collection of tiff files generated by the LSM pipeline into ZARR.

    Orientation
    -----------
    The anatomical orientation of the slice is given in terms of RAS axes.

    It is a combination of two letters from the set
    `{"L", "R", "A", "P", "I", "S"}`, where

    * the first letter corresponds to the horizontal dimension and
        indicates the anatomical meaning of the _right_ of the jp2 image,
    * the second letter corresponds to the vertical dimension and
        indicates the anatomical meaning of the _bottom_ of the jp2 image.

    We also provide the aliases

    * `"coronal"` == `"LI"`
    * `"axial"` == `"LP"`
    * `"sagittal"` == `"PI"`

    The orientation flag is only useful when converting to nifti-zarr.

    Parameters
    ----------
    inp
        Path to the root directory, which contains a collection of
        subfolders named `*_z{:02d}_y{:02d}*`, each containing a
        collection of files named `*_plane{:03d}_c{:d}.tiff`.
    out
        Path to the output Zarr directory [<INP>.ome.zarr]
    max_load
        Maximum input chunk size when building pyramid
    orientation
        Orientation of the slice
    center
        Set RAS[0, 0, 0] at FOV center
    voxel_size
        Voxel size along the X, Y and Z dimension, in micron.
    """
    zarr_config = utils.zarr.zarr_config.update(zarr_config, **kwargs)
    chunk: int = zarr_config.chunk[0]
    compressor: str = zarr_config.compressor
    compressor_opt: str = zarr_config.compressor_opt
    nii: bool = zarr_config.nii

    if isinstance(compressor_opt, str):
        compressor_opt = ast.literal_eval(compressor_opt)

    CHUNK_PATTERN = re.compile(
        r"^(?P<prefix>\w*)"
        r"_run(?P<run>[0-9]+)"
        r"_?"
        r"_y(?P<y>[0-9]+)"
        r"_z(?P<z>[0-9]+)"
        r"(?P<suffix>\w*)$"
    )

    all_tiles_folders_names = sorted(glob(os.path.join(inp, "*_y*_z*_HR/")))
    if not all_tiles_folders_names:
        raise ValueError("No tile folder found")

    all_tiles_info = []
    tiles_info_by_index = {}
    TileInfo = namedtuple(
        "TileInfo",
        ["prefix", "run", "y", "z", "suffix", "filename", "reader"]
    )
    for tile_folder_name in all_tiles_folders_names:
        if tile_folder_name.endswith(r"/"):
            tile_folder_name = tile_folder_name[:-1]
        parsed = CHUNK_PATTERN.fullmatch(os.path.basename(tile_folder_name))
        tile = TileInfo(
            parsed.group("prefix"),
            int(parsed.group("run")),
            int(parsed.group("y")),
            int(parsed.group("z")),
            parsed.group("suffix"),
            tile_folder_name,
            SpoolSetInterpreter(tile_folder_name)
        )
        all_tiles_info.append(tile)
        # check no duplication
        if (tile.y, tile.z) in tiles_info_by_index:
            raise ValueError(
                f"Duplicate tile, file {tile.filename} conflicts with {tiles_info_by_index[(tile.y, tile.z)].filename}")
        tiles_info_by_index[(tile.y, tile.z)] = tile

    # default output name
    if not out:
        out = all_tiles_info[0].prefix + all_tiles_info[0].suffix
        out += ".nii.zarr" if nii else ".ome.zarr"
    nii = nii or out.endswith(".nii.zarr")

    # parse all individual file names
    z_tiles = set(tile.z for tile in all_tiles_info)
    y_tiles = set(tile.y for tile in all_tiles_info)
    min_y_tile, max_y_tile = min(y_tiles), max(y_tiles)
    min_z_tile, max_z_tile = min(z_tiles), max(z_tiles)
    num_y_tiles, num_z_tiles = len(y_tiles), len(z_tiles)

    # store dtypes in each tile where keys are dtypes and values are the tile indices
    dtypes = defaultdict(list)
    expected_sx = 0
    expected_sy = {}
    expected_sz = {}
    all_shapes = np.empty((num_y_tiles, num_z_tiles, 3), dtype=int)

    for z_tile in range(min_z_tile, max_z_tile + 1):
        for y_tile in range(min_y_tile, max_y_tile + 1):
            rel_y_tile_idx = y_tile - min_y_tile
            rel_z_tile_idx = z_tile - min_z_tile

            tile = tiles_info_by_index.get((y_tile, z_tile))
            if tile is None:
                warnings.warn(f"Missing tile {y_tile}, {z_tile}")
                continue
            reader = tile.reader
            # tile array is x, z, y
            sx, sz, sy = reader.spool_shape
            sx *= len(list(reader._get_spool_names_in_order()))
            dt = reader.dtype
            # Collect shapes and dtypes.
            all_shapes[rel_y_tile_idx, rel_z_tile_idx] = sx, sy, sz
            expected_sx = sx
            expected_sy[y_tile] = sy
            expected_sz[z_tile] = sz
            dtypes[dt].append((y_tile, z_tile))

    if len(dtypes) != 1:
        warnings.warn("Two or more dtypes in tiles:\n" + str(dict(dtypes)))

    diff_sx = (all_shapes[:, :, 0] != expected_sx)
    if diff_sx.any():
        y_idxs, z_idxs = np.where(diff_sx)
        raise ValueError(
            f"Inconsistent x shapes at indices: {list(zip(y_idxs, z_idxs))}")
    for y_tile in range(min_y_tile, max_y_tile + 1):
        if y_tile not in expected_sy:
            raise ValueError(f"Missing y tile {y_tile}")
        diff_sy = (all_shapes[:, :, 1] != expected_sy[y_tile])
        if diff_sy.any():
            y_idxs, z_idxs = np.where(diff_sy)
            raise ValueError(
                f"Inconsistent y shapes at tiles: {list(zip(y_idxs, z_idxs))}")
    for z_tile in range(min_z_tile, max_z_tile + 1):
        if z_tile not in expected_sz:
            raise ValueError(f"Missing z tile {z_tile}")
        diff_sz = (all_shapes[:, :, 2] != expected_sz[z_tile])
        if diff_sy.any():
            y_idxs, z_idxs = np.where(diff_sz)
            raise ValueError(
                f"Inconsistent z shapes at tiles: {list(zip(y_idxs, z_idxs))}")

    # Calculate full shape
    full_shape_x = expected_sx
    full_shape_y = sum(expected_sy.values()) - (num_y_tiles - 1) * overlap
    full_shape_z = sum(expected_sz.values())
    fullshape = [full_shape_z, full_shape_y, full_shape_x]

    dtype = next(iter(dtypes))

    # Prepare Zarr group
    omz = zarr.storage.DirectoryStore(out)
    omz = zarr.group(store=omz, overwrite=True)
    print(out)
    # Prepare chunking options
    opt = {
        "chunks": [chunk] * 3,
        "dimension_separator": r"/",
        "order": "F",
        "dtype": np.dtype(dtype).str,
        "fill_value": None,
        "compressor": make_compressor(compressor, **compressor_opt),
    }

    # write first level
    omz.create_dataset("0", shape=fullshape, **opt)
    array = omz["0"]
    print("Write level 0 with shape", fullshape)

    for i, tile_info in enumerate(all_tiles_info):
        rel_y_tile_idx = tile_info.y - min_y_tile
        rel_z_tile_idx = tile_info.z - min_z_tile
        dat = tile_info.reader.assemble()

        if num_y_tiles != 1 and overlap != 0:
            # if not first y tile, crop half overlapped rows at the beginning
            if tile_info.y != min_y_tile:
                dat = dat[:, overlap // 2:, :]
            # if not last y tile, crop half overlapped rows at the end
            # if overlap is odd, we need to crop an extra row
            if tile_info.z != max_z_tile:
                dat = dat[:, :-overlap // 2 - (overlap % 2), :]
        ystart = sum(expected_sy[min_y_tile + y_idx] - overlap for y_idx in
                     range(rel_y_tile_idx))
        zstart = sum(expected_sz[min_z_tile + z_idx] for z_idx in range(rel_z_tile_idx))

        if rel_y_tile_idx != 0:
            ystart += overlap // 2
        print(
            f"Write plane "
            f"( {zstart} :{zstart + dat.shape[0]}, {ystart}:{ystart + dat.shape[1]})",
            end="\r",
        )
        slicer = (
            slice(zstart, zstart + dat.shape[0]),
            slice(ystart, ystart + dat.shape[1]),
            slice(None),
        )
        array[slicer] = dat
    print("")

    # build pyramid using median windows
    generate_pyramid(omz)
    write_ome_metadata(omz, axes = ["z","y","x"],space_scale=voxel_size)

    # Write NIfTI-Zarr header:
    if not nii:
        return

    header = default_nifti_header(omz["0"], omz)
    shape = list(reversed(omz["0"].shape))
    shape = shape[:3] + [1] + shape[3:]  # insert time dimension
    affine = orientation_to_affine(orientation, *voxel_size)
    if center:
        affine = center_affine(affine, shape[:3])
    header.set_data_shape(shape)
    header.set_data_dtype(omz["0"].dtype)
    header.set_qform(affine)
    header.set_sform(affine)
    header.set_xyzt_units(nib.nifti1.unit_codes.code["micron"])

    write_nifti_header(omz, header)

